// voice.js
console.log("ðŸŽ™ Voice module loaded");

// ðŸŽ§ ÐžÐ·Ð²ÑƒÑ‡Ð¸Ð²Ð°Ð½Ð¸Ðµ Ð¿ÐµÑ€ÐµÐ²Ð¾Ð´Ð°
function speakOutput() {
  const output = document.getElementById("output").textContent;
  const utterance = new SpeechSynthesisUtterance(output);
  utterance.lang = document.getElementById("targetLang").value || "en";
  speechSynthesis.speak(utterance);
}

// ðŸŽ¤ Ð“Ð¾Ð»Ð¾ÑÐ¾Ð²Ð¾Ð¹ Ð²Ð²Ð¾Ð´ (Speech-to-Text)
const micButton = document.getElementById("mic-button");
const inputField = document.getElementById("inputText");

let recognition;
let isListening = false;

if (!("webkitSpeechRecognition" in window)) {
  micButton.disabled = true;
  micButton.title = "ðŸŽ¤ Ð‘Ñ€Ð°ÑƒÐ·ÐµÑ€ Ð½Ðµ Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶Ð¸Ð²Ð°ÐµÑ‚ Ð³Ð¾Ð»Ð¾ÑÐ¾Ð²Ð¾Ð¹ Ð²Ð²Ð¾Ð´";
} else {
  recognition = new webkitSpeechRecognition();
  recognition.continuous = false;
  recognition.interimResults = false;

  recognition.onstart = () => {
    isListening = true;
    micButton.textContent = "ðŸ›‘";
  };

  recognition.onresult = (event) => {
    const transcript = event.results[0][0].transcript;
    inputField.value += (inputField.value ? " " : "") + transcript;
    micButton.textContent = "ðŸŽ¤";
    isListening = false;
  };

  recognition.onerror = (e) => {
    console.error("ðŸŽ™ ÐžÑˆÐ¸Ð±ÐºÐ° Ñ€Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð²Ð°Ð½Ð¸Ñ:", e.error);
    micButton.textContent = "ðŸŽ¤";
    isListening = false;
  };

  recognition.onend = () => {
    micButton.textContent = "ðŸŽ¤";
    isListening = false;
  };

  micButton.addEventListener("click", () => {
    if (isListening) {
      recognition.stop();
    } else {
      recognition.lang = document.getElementById("sourceLang").value || "auto";
      recognition.start();
    }
  });
}